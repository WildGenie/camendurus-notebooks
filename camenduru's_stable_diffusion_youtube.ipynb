{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_stable_diffusion_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "6Ri_0rRMb2x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq git+https://github.com/camenduru/diffusers.git\n",
        "!pip install -qq transformers ftfy\n",
        "\n",
        "import torch, os, gc, requests, subprocess\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import autocast\n",
        "from IPython.display import clear_output, HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=\"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\").to(\"cuda\")\n",
        "pipe.safety_checker = lambda images, **kwargs: [images, [False] * len(images)]\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "F1WTBlIF4SyA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = 'MTAyMDM1NTQ2MzI4MTM3NzM5MA.G_g0Hg.gpPMPLtyzn7aYsgGPGPoJd05ENUVRiN1NtrFTs' #@param {type: 'string'}\n",
        "header = {\"authorization\": f\"Bot {token}\"}\n",
        "channel_id = 1020517233757261896 #@param {type: 'integer'}\n",
        "by = 'camenduru' #@param {type: 'string'}\n",
        "\n",
        "folder = '001' #@param {type: 'string'}\n",
        "if os.path.exists(f\"{folder}\") == False:\n",
        "  os.mkdir(f\"{folder}\")\n",
        "name = max([int(f[:f.index('.')]) for f in os.listdir(f\"{folder}\")], default=0)\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "metadata = PngInfo()\n",
        "\n",
        "is_tile = False #@param {type: 'boolean'}\n",
        "if(is_tile):\n",
        "\tdef patch_conv(cls):\n",
        "\t\tinit = cls.__init__\n",
        "\t\tdef __init__(self, *args, **kwargs):\n",
        "\t\t\treturn init(self, *args, **kwargs, padding_mode='circular')\n",
        "\t\tcls.__init__ = __init__\n",
        "\tpatch_conv(torch.nn.Conv2d)\n",
        " \n",
        "height = 512 #@param {type: 'integer'}\n",
        "width = 512 #@param {type: 'integer'}\n",
        "\n",
        "def generate(prompt, name):\n",
        "  metadata.add_text(\"Prompt\", f\"{prompt}\")\n",
        "  metadata.add_text(\"by\", f\"{by}\")\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  with autocast(\"cuda\"):\n",
        "    image = pipe(prompt, height=height, width=width, num_inference_steps=50, eta=0.0, guidance_scale=7.5)[\"sample\"][0]\n",
        "  image.save(f\"{folder}/{name:04}.png\", pnginfo=metadata)\n",
        "  files = {f\"{folder}/{name:04}.png\" : open(f\"{folder}/{name:04}.png\", \"rb\").read()}\n",
        "  payload = {\"content\":f\"{prompt}\"}\n",
        "  r = requests.post(f\"https://discord.com/api/v9/channels/{channel_id}/messages\", data=payload, headers=header, files=files).text\n",
        "  # os.remove(f\"{folder}/{name:04}.png\")\n",
        "  clear_output()\n",
        "\n",
        "max_files = 25 #@param {type: 'integer'}\n",
        "is_from_prompts_txt = False #@param {type: 'boolean'}\n",
        "prompts_txt = 'prompts.txt' #@param {type: 'string'}\n",
        "if(is_from_prompts_txt):\n",
        "  while name < max_files:\n",
        "    with open(f'{prompts_txt}', \"r\") as file:\n",
        "      prompts = file.readlines()\n",
        "    for prompt in prompts:\n",
        "      name += 1\n",
        "      generate(prompt, name)\n",
        "else:\n",
        "  prompt = 'monsters by Mike Winkelmann Beeple, ultra-detailed pen and ink illustration' #@param {type: 'string'}\n",
        "  while name < max_files:\n",
        "    name += 1\n",
        "    generate(prompt, name)\n",
        "\n",
        "video_folder = '/content/gdrive/MyDrive/AI/StableDiffusion/videos' #@param {type: 'string'}\n",
        "if os.path.exists(f\"{video_folder}\") == False:\n",
        "  os.mkdir(f\"{video_folder}\")\n",
        "\n",
        "fps = 1/3\n",
        "scale = '512:512' #@param {type: 'string'}\n",
        "cmd = ['ffmpeg','-y','-vcodec','png','-r',f'{fps}','-i',f'{folder}/%04d.png','-c:v','libx264','-pix_fmt','yuv420p','-vf',f'scale={scale}','-preset','ultrafast',f'{video_folder}/{folder}.mp4']\n",
        "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "stdout, stderr = process.communicate()\n",
        "if process.returncode != 0:\n",
        "  print(stderr)\n",
        "  raise RuntimeError(stderr)\n",
        "\n",
        "mp4 = open(f'{video_folder}/{folder}.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f'<video width={width} controls><source src=\"{data_url}\" type=\"video/mp4\"></video>')"
      ],
      "metadata": {
        "id": "7tOGrS5lA6-D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
