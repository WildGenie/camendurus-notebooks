{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "HqdeaaCIjQp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers transformers ftfy\n",
        "\n",
        "import os, torch\n",
        "from PIL import Image\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "\n",
        "model_path = \"camenduru/sd15\"\n",
        "tokenizer = CLIPTokenizer.from_pretrained(model_path, subfolder=\"tokenizer\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(model_path, subfolder=\"text_encoder\", torch_dtype=torch.float16)\n",
        "\n",
        "def load_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, token=None):\n",
        "  filename, file_extension = os.path.splitext(learned_embeds_path)\n",
        "  loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
        "  if (file_extension == \".pt\"):\n",
        "    string_to_token = loaded_learned_embeds['string_to_token']\n",
        "    string_to_param = loaded_learned_embeds['string_to_param']\n",
        "    trained_token = list(string_to_token.keys())[0]\n",
        "    embeds = string_to_param[trained_token]\n",
        "    embeds = embeds.detach()\n",
        "    embeds = embeds[1]\n",
        "  else:\n",
        "    trained_token = list(loaded_learned_embeds.keys())[0]\n",
        "    embeds = loaded_learned_embeds[trained_token]\n",
        "\n",
        "  dtype = text_encoder.get_input_embeddings().weight.dtype\n",
        "  embeds.to(dtype)\n",
        "  token = token if token is not None else trained_token\n",
        "  num_added_tokens = tokenizer.add_tokens(token)\n",
        "  if num_added_tokens == 0:\n",
        "    raise ValueError(f\"The tokenizer already contains the token {token}.\")\n",
        "  text_encoder.resize_token_embeddings(len(tokenizer))\n",
        "  token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "  text_encoder.get_input_embeddings().weight.data[token_id] = embeds\n",
        "\n",
        "load_learned_embed_in_clip(\"/content/learned_embeds.bin\", text_encoder, tokenizer)\n",
        "load_learned_embed_in_clip(\"/content/bad_prompt_version2.pt\", text_encoder, tokenizer, \"bad_prompt\")\n",
        "load_learned_embed_in_clip(\"/content/4tnght.bin\", text_encoder, tokenizer, \"4tNGHT\")"
      ],
      "metadata": {
        "id": "oRljt9Kfhh5r"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16, text_encoder=text_encoder, tokenizer=tokenizer).to(\"cuda\")"
      ],
      "metadata": {
        "id": "SUu2dkv5DOe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with torch.autocast(\"cuda\"):\n",
        "#   image = pipe(\"<midjourney-style> house\").images[0]\n",
        "# display(image)\n",
        "\n",
        "# with torch.autocast(\"cuda\"):\n",
        "#   image = pipe(\"hand\", negative_prompt=\"bad_prompt\").images[0]\n",
        "# display(image)\n",
        "\n",
        "# with torch.autocast(\"cuda\"):\n",
        "#   image = pipe(\"hand\").images[0]\n",
        "# display(image)\n",
        "\n",
        "with torch.autocast(\"cuda\"):\n",
        "  image = pipe(\"<4tNGHT>\").images[0]\n",
        "display(image)"
      ],
      "metadata": {
        "id": "wj-Bz_5vhdcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_learned_embed_in_clip(learned_embeds_path, text_encoder, tokenizer, token=None):\n",
        "  filename, file_extension = os.path.splitext(learned_embeds_path)\n",
        "  loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
        "  print(loaded_learned_embeds)\n",
        "\n",
        "test_learned_embed_in_clip(\"/content/learned_embeds.bin\", text_encoder, tokenizer)\n",
        "test_learned_embed_in_clip(\"/content/bad_prompt_version2.pt\", text_encoder, tokenizer, \"bad_prompt\")\n",
        "test_learned_embed_in_clip(\"/content/4tnght.pt\", text_encoder, tokenizer, \"4tNGHT\")"
      ],
      "metadata": {
        "id": "vjtrVr7ZECFn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
