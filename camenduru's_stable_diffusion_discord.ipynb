{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camenduru/notebooks/blob/main/camenduru's_stable_diffusion_discord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq git+https://github.com/camenduru/diffusers.git\n",
        "!pip install -qq transformers ftfy\n",
        "\n",
        "import torch, os, gc, requests, random\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import autocast\n",
        "from IPython.display import clear_output\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=\"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\").to(\"cuda\")\n",
        "pipe.safety_checker = lambda images, **kwargs: [images, [False] * len(images)]\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "F1WTBlIF4SyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = '' #@param {type: 'string'}\n",
        "header = {\"authorization\": f\"Bot {token}\"}\n",
        "channel_id = 0 #@param {type: 'integer'}\n",
        "by = 'camenduru' #@param {type: 'string'}\n",
        "\n",
        "image_folder = '001' #@param {type: 'string'}\n",
        "if os.path.exists(f\"{image_folder}\") == False:\n",
        "  os.mkdir(f\"{image_folder}\")\n",
        "name = max([int(f[:f.index('.')]) for f in os.listdir(f\"{image_folder}\")], default=0)\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "metadata = PngInfo()\n",
        "\n",
        "is_tile = False #@param {type: 'boolean'}\n",
        "if(is_tile):\n",
        "\tdef patch_conv(cls):\n",
        "\t\tinit = cls.__init__\n",
        "\t\tdef __init__(self, *args, **kwargs):\n",
        "\t\t\treturn init(self, *args, **kwargs, padding_mode='circular')\n",
        "\t\tcls.__init__ = __init__\n",
        "\tpatch_conv(torch.nn.Conv2d)\n",
        " \n",
        "height = 512 #@param {type: 'integer'}\n",
        "width = 512 #@param {type: 'integer'}\n",
        "\n",
        "def generate(prompt, name):\n",
        "  metadata.add_text(\"Prompt\", f\"{prompt}\")\n",
        "  metadata.add_text(\"by\", f\"{by}\")\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  with autocast(\"cuda\"):\n",
        "    image = pipe(prompt, height=height, width=width, num_inference_steps=50, eta=0.0, guidance_scale=7.5)[\"sample\"][0]\n",
        "  image.save(f\"{image_folder}/{name:04}.png\", pnginfo=metadata)\n",
        "  files = {f\"{image_folder}_{name:04}.png\" : open(f\"{image_folder}/{name:04}.png\", \"rb\").read()}\n",
        "  payload = {\"content\":f\"{prompt}\"}\n",
        "  r = requests.post(f\"https://discord.com/api/v9/channels/{channel_id}/messages\", data=payload, headers=header, files=files).text\n",
        "  clear_output()\n",
        "\n",
        "is_from_prompts_txt = True #@param {type: 'boolean'}\n",
        "prompts_txt = 'prompts.txt' #@param {type: 'string'}\n",
        "if(is_from_prompts_txt):\n",
        "  while True:\n",
        "    with open(f'{prompts_txt}', \"r\") as file:\n",
        "      prompts = file.readlines()\n",
        "    for prompt in prompts:\n",
        "      name += 1\n",
        "      generate(prompt, name)\n",
        "else:\n",
        "  prompt = '' #@param {type: 'string'}\n",
        "  while True:\n",
        "    name += 1\n",
        "    generate(prompt, name)"
      ],
      "metadata": {
        "id": "7tOGrS5lA6-D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
